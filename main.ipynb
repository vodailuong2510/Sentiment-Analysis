{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info = True, as_supervised = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl8tkoAeJqsu",
        "outputId": "fd819035-1373-4ef7-dd10-736299b2cc1a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "train_data, test_data = dataset['train'], dataset['test']\n",
        "\n",
        "train_sentences=[]\n",
        "test_sentences=[]\n",
        "\n",
        "train_labels=[]\n",
        "test_labels=[]\n",
        "\n",
        "for s,l in train_data:\n",
        "  train_sentences.append(str(s.numpy()))\n",
        "  train_labels.append(l.numpy())\n",
        "\n",
        "for s,l in test_data:\n",
        "  test_sentences.append(str(s.numpy()))\n",
        "  test_labels.append(l.numpy())\n",
        "\n",
        "vocab_size=10000\n",
        "embedding_dim = 64\n",
        "max_length = 150\n"
      ],
      "metadata": {
        "id": "SR6CJCUKJ8-d"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)"
      ],
      "metadata": {
        "id": "Dald14ReTdYq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "\n",
        "train_sequences= tokenizer.texts_to_sequences(train_sentences)\n",
        "\n",
        "padded_train_sequences=pad_sequences(train_sequences, maxlen=max_length, truncating='post', padding=\"post\")\n",
        "\n",
        "test_sequences= tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "padded_test_sequences=pad_sequences(test_sequences, maxlen=max_length, truncating='post', padding=\"post\")"
      ],
      "metadata": {
        "id": "UWX-oxrjKSA4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional, Dropout"
      ],
      "metadata": {
        "id": "z-_dzLODMEKg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "cSY5Xef-MU_H"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['acc'])\n",
        "model.fit(padded_train_sequences, train_labels, epochs=10, validation_data=(padded_test_sequences, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyQsmVPWU_Nc",
        "outputId": "24e4ee5b-5592-4626-87aa-7dfbeca4731e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 67s 77ms/step - loss: 0.5157 - acc: 0.7377 - val_loss: 0.4433 - val_acc: 0.7870\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 37s 47ms/step - loss: 0.3502 - acc: 0.8514 - val_loss: 0.5000 - val_acc: 0.7985\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.2823 - acc: 0.8868 - val_loss: 0.5421 - val_acc: 0.7906\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 31s 40ms/step - loss: 0.2225 - acc: 0.9156 - val_loss: 0.6039 - val_acc: 0.7898\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1718 - acc: 0.9382 - val_loss: 0.6451 - val_acc: 0.7677\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 0.1264 - acc: 0.9571 - val_loss: 0.7368 - val_acc: 0.7850\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 31s 39ms/step - loss: 0.0994 - acc: 0.9662 - val_loss: 0.7738 - val_acc: 0.7624\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.0873 - acc: 0.9716 - val_loss: 0.9353 - val_acc: 0.7811\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 31s 39ms/step - loss: 0.0671 - acc: 0.9786 - val_loss: 0.8603 - val_acc: 0.7764\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 0.0547 - acc: 0.9832 - val_loss: 0.8599 - val_acc: 0.7789\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cd1ac281570>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"Sentiment_Analysis.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsfpoa0nVA2E",
        "outputId": "1b7a2842-ec4a-4630-ea14-d61108aebe9b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}