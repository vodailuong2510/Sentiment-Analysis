# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TP08opLZzsgx5sa0_nCtItkAsprgHq-6
"""

from google.colab import drive
drive.mount("/content/drive")

cd/content/drive/MyDrive/Lượng và hành trình nghiêm cứu khoa học/Sentiment Analysis

import tensorflow_datasets as tfds

imdb, info = tfds.load('imdb_reviews', with_info=True, as_supervised=True)

import numpy as np

train_data, test_data=imdb['train'], imdb['test']

train_sentences=[]
test_sentences=[]

train_labels=[]
test_labels=[]

for s,l in train_data:
  train_sentences.append(str(s.numpy()))
  train_labels.append(l.numpy())

for s,l in test_data:
  test_sentences.append(str(s.numpy()))
  test_labels.append(l.numpy())

train_labels = np.array(train_labels)
test_labels = np.array(test_labels)

vocab_size=10000
embedding_dim = 64
max_length = 150

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=vocab_size, oov_token="<OOV>")

tokenizer.fit_on_texts(train_sentences)

train_sequences= tokenizer.texts_to_sequences(train_sentences)

padded_train_sequences=pad_sequences(train_sequences, maxlen=max_length, truncating='post', padding="post")

test_sequences= tokenizer.texts_to_sequences(test_sentences)

padded_test_sequences=pad_sequences(test_sequences, maxlen=max_length, truncating='post', padding="post")

from tensorflow.keras.models import Sequential

from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Embedding
from tensorflow.keras.layers import Dense

model= Sequential()

model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))

model.add(Flatten())

model.add(Dense(10, activation='relu'))

model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics='acc')

model.summary()

model.fit(padded_train_sequences, train_labels, epochs=10, validation_data=(padded_test_sequences, test_labels))

model.save("Sentiment_Analysis.h5")

test_sen=[input()]
test_seq=tokenizer.texts_to_sequences(test_sen)
padded_test_seq=pad_sequences(test_seq, maxlen=max_length, truncating='post', padding='post')

model.predict(padded_test_seq)